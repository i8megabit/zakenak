# Параметры релиза
release:
  name: ollama
  namespace: prod

# Deployment control
enabled: false  # Set to false to disable the Ollama deployment in Kubernetes

# External Ollama configuration
externalOllama:
  enabled: true
  host: "host.docker.internal"  # This resolves to the Docker host from within Kubernetes
  port: 11434

# Основные настройки приложения
image:
  repository: ollama/ollama
  tag: latest
  pullPolicy: IfNotPresent

# Настройки развертывания
deployment:
  replicas: 1
  resources:
    limits:
      cpu: "8"
      memory: "16Gi"
      nvidia.com/gpu: "1"
    requests:
      cpu: "4"
      memory: "8Gi"
  # Add GPU node selector configuration
  gpuNodeSelector:
    enabled: false  # Set to false by default to avoid scheduling issues
    labelKey: "nvidia.com/gpu"
    labelValue: "present"
  envFrom:
    - configMapRef:
        name: gpu-config
  env:
    - name: OLLAMA_HOST
      value: "0.0.0.0"

# Настройки сервиса
service:
  type: NodePort
  port: 11434
  targetPort: 11434
  nodePort: 30434

# Настройки Ingress
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: local-ca-issuer
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  hosts:
    - host: ollama.prod.local
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: ollama-tls
      hosts:
        - ollama.prod.local

# Настройки хранилища для моделей
persistence:
  enabled: false  # Disabled since we're using hostPath
  size: 100Gi  # Increased storage for larger models
  storageClass: ""
  accessModes:
    - ReadWriteOnce

# Настройки безопасности
securityContext:
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000

# Настройки сети
networkPolicy:
  enabled: true
  allowedNamespaces:
    - prod